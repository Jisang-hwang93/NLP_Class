{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06 TF-IDF Practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM8TfaGe9iIa2nLm6QJe+Qm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jisang-hwang93/NLP_Class/blob/master/06%20TF%20IDF%20Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpJWXKsNc_ju",
        "colab_type": "text"
      },
      "source": [
        "# **Term Frequency - Inverse Document Frequency**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4X3zhR7MvW",
        "colab_type": "text"
      },
      "source": [
        "## **1. TF-IDF 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpU2G-66dFeG",
        "colab_type": "text"
      },
      "source": [
        "### **1-1. TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z69wPq4MN9JH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문서 리스트 생성\n",
        "doc = [\"The cat sat on my face I hate a cat\", \"The dog sat on my bed I love a dog\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFgSebdzdPcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "7822afb5-c03f-4b80-b820-30ba73902641"
      },
      "source": [
        "# 문서 토큰화\n",
        "doc_token = []\n",
        "tmp = []\n",
        "\n",
        "for doc_content in doc:\n",
        "    doc_token.append(doc_content.split())\n",
        "    tmp += doc_content.split()\n",
        "\n",
        "word_ls = list(set(tmp))\n",
        "\n",
        "doc_token, word_ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['The', 'cat', 'sat', 'on', 'my', 'face', 'I', 'hate', 'a', 'cat'],\n",
              "  ['The', 'dog', 'sat', 'on', 'my', 'bed', 'I', 'love', 'a', 'dog']],\n",
              " ['dog',\n",
              "  'my',\n",
              "  'on',\n",
              "  'The',\n",
              "  'I',\n",
              "  'hate',\n",
              "  'a',\n",
              "  'cat',\n",
              "  'sat',\n",
              "  'face',\n",
              "  'bed',\n",
              "  'love'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_0kvGVsSFWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9142b60-a2b0-4b07-db31-75beaa983df8"
      },
      "source": [
        "# 문서별 단어 빈도수\n",
        "dic = []\n",
        "\n",
        "for i in range(len(doc_token)):\n",
        "    words_count = [0 for a in range(len(word_ls))]\n",
        "    for j in range(len(word_ls)):\n",
        "        words_count[j] = doc_token[i].count(word_ls[j])\n",
        "    dic.append(words_count)\n",
        "\n",
        "dic"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0], [2, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lV7SW8SSehW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "505326ed-bc56-4f76-de58-cb2f855e0d63"
      },
      "source": [
        "# 전체 토큰 빈도 계산\n",
        "total = []\n",
        "\n",
        "for i in range(len(dic)):\n",
        "    total_num = 0\n",
        "    for j in words_count:\n",
        "        total_num += j\n",
        "    total.append(total_num)\n",
        "\n",
        "total"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnCtDsTASs8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6a0ded6a-f0ae-4bb8-9e4b-8dbc3f893375"
      },
      "source": [
        "# TF 계산\n",
        "tf = []\n",
        "\n",
        "for i in range(len(dic)):\n",
        "    tf_tmp = []\n",
        "    for dic_value in dic[i]:\n",
        "        tf_tmp.append(dic_value / total[i])\n",
        "    tf.append(tf_tmp)\n",
        "\n",
        "tf"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.0, 0.0],\n",
              " [0.2, 0.1, 0.1, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBkDOEMal5_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "f1f770c0-46f2-4501-d070-2b250cfdda7d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# IDF 계산\n",
        "\n",
        "count_idf = [0 for a in range(len(word_ls))]\n",
        "\n",
        "for i in range(len(doc_token)):\n",
        "    for j in range(len(word_ls)):\n",
        "        if word_ls[j] in doc_token[i]:\n",
        "            count_idf[j] += 1\n",
        "    \n",
        "idf = [0 for a in range(len(word_ls))]\n",
        "\n",
        "for i in range(len(count_idf)):\n",
        "    idf[i] = -np.log(count_idf[i] / len(doc_token))\n",
        "\n",
        "idf"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6931471805599453,\n",
              " -0.0,\n",
              " -0.0,\n",
              " -0.0,\n",
              " -0.0,\n",
              " 0.6931471805599453,\n",
              " -0.0,\n",
              " 0.6931471805599453,\n",
              " -0.0,\n",
              " 0.6931471805599453,\n",
              " 0.6931471805599453,\n",
              " 0.6931471805599453]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1VxS5M1ao4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "1c699264-c4b3-430e-dbe3-3368d919e1a8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TF-IDF\n",
        "tf_idf = []\n",
        "\n",
        "for i in range(len(doc_token)):\n",
        "    count_tfidf = [0 for a in range(len(word_ls))]\n",
        "    for j in range(len(word_ls)):\n",
        "        count_tfidf[j] = tf[i][j] * idf[j]\n",
        "    tf_idf.append(count_tfidf)\n",
        "\n",
        "tf_idf"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0,\n",
              "  -0.0,\n",
              "  -0.0,\n",
              "  -0.0,\n",
              "  -0.0,\n",
              "  0.06931471805599453,\n",
              "  -0.0,\n",
              "  0.13862943611198905,\n",
              "  -0.0,\n",
              "  0.06931471805599453,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.13862943611198905,\n",
              "  -0.0,\n",
              "  -0.0,\n",
              "  -0.0,\n",
              "  -0.0,\n",
              "  0.0,\n",
              "  -0.0,\n",
              "  0.0,\n",
              "  -0.0,\n",
              "  0.0,\n",
              "  0.06931471805599453,\n",
              "  0.06931471805599453]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3eO8AwRs6G2",
        "colab_type": "text"
      },
      "source": [
        "### **1-2. TF-IDF 결과 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT-Knhz8nTjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "866f7743-3298-490e-906a-740b87adbacf"
      },
      "source": [
        "for i in range(len(doc_token)):\n",
        "    print(\"=========== doc {} ===========\".format(i))\n",
        "    df = pd.concat((pd.DataFrame(tf[i], index=word_ls, columns=['TF']), pd.DataFrame(idf, index=word_ls, columns=['idf']), pd.DataFrame(tf_idf[i],  index=word_ls, columns=['TF-IDF'])), axis=1)\n",
        "    print(df)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========== doc 0 ===========\n",
            "       TF       idf    TF-IDF\n",
            "dog   0.0  0.693147  0.000000\n",
            "my    0.1 -0.000000 -0.000000\n",
            "on    0.1 -0.000000 -0.000000\n",
            "The   0.1 -0.000000 -0.000000\n",
            "I     0.1 -0.000000 -0.000000\n",
            "hate  0.1  0.693147  0.069315\n",
            "a     0.1 -0.000000 -0.000000\n",
            "cat   0.2  0.693147  0.138629\n",
            "sat   0.1 -0.000000 -0.000000\n",
            "face  0.1  0.693147  0.069315\n",
            "bed   0.0  0.693147  0.000000\n",
            "love  0.0  0.693147  0.000000\n",
            "=========== doc 1 ===========\n",
            "       TF       idf    TF-IDF\n",
            "dog   0.2  0.693147  0.138629\n",
            "my    0.1 -0.000000 -0.000000\n",
            "on    0.1 -0.000000 -0.000000\n",
            "The   0.1 -0.000000 -0.000000\n",
            "I     0.1 -0.000000 -0.000000\n",
            "hate  0.0  0.693147  0.000000\n",
            "a     0.1 -0.000000 -0.000000\n",
            "cat   0.0  0.693147  0.000000\n",
            "sat   0.1 -0.000000 -0.000000\n",
            "face  0.0  0.693147  0.000000\n",
            "bed   0.1  0.693147  0.069315\n",
            "love  0.1  0.693147  0.069315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSH9mxW59AaI",
        "colab_type": "text"
      },
      "source": [
        "## **2. TF-IDF Class화**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAraKI75svSF",
        "colab_type": "text"
      },
      "source": [
        "### **2-1. TF-IDF Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XupbMak0UgSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class tf_idf():\n",
        "    def __init__(self):\n",
        "        self.doc_token = []\n",
        "        self.word_ls = []\n",
        "        self.dic = []\n",
        "        self.total = []\n",
        "        self.tf = []\n",
        "        self.idf = []\n",
        "        self.tf_idf = []\n",
        "\n",
        "    # 문서 토큰화\n",
        "    def make_token(self, doc):\n",
        "        tmp = []\n",
        "        for doc_content in doc:\n",
        "            self.doc_token.append(doc_content.split())\n",
        "            tmp += doc_content.split()\n",
        "        self.word_ls = list(set(tmp))\n",
        "\n",
        "        return self.doc_token, self.word_ls\n",
        "\n",
        "    # 문서별 단어 빈도수\n",
        "    def count_word(self):\n",
        "        for i in range(len(self.doc_token)):\n",
        "            words_count = [0 for a in range(len(self.word_ls))]\n",
        "            for j in range(len(self.word_ls)):\n",
        "                words_count[j] = self.doc_token[i].count(self.word_ls[j])\n",
        "            self.dic.append(words_count)\n",
        "\n",
        "        return self.dic\n",
        "\n",
        "    # 전체 토큰 개수 계산\n",
        "    def count_total(self):\n",
        "        for i in range(len(self.dic)):\n",
        "            total_num = 0\n",
        "            for j in self.dic[i]:\n",
        "                total_num += j\n",
        "            self.total.append(total_num)\n",
        "\n",
        "        return self.total\n",
        "\n",
        "    # TF 계산\n",
        "    def cal_tf(self):\n",
        "        for i in range(len(self.dic)):\n",
        "            tf_tmp = []\n",
        "            for dic_value in self.dic[i]:\n",
        "                tf_tmp.append(dic_value / self.total[i])\n",
        "            self.tf.append(tf_tmp)\n",
        "\n",
        "        return self.tf\n",
        "\n",
        "    # IDF 계산\n",
        "    def cal_idf(self):\n",
        "        count_idf = [0 for a in range(len(self.word_ls))]\n",
        "        for i in range(len(self.doc_token)):\n",
        "            for j in range(len(self.word_ls)):\n",
        "                if self.word_ls[j] in self.doc_token[i]:\n",
        "                    count_idf[j] += 1\n",
        "            \n",
        "        self.idf = [0 for a in range(len(self.word_ls))]\n",
        "        for i in range(len(count_idf)):\n",
        "            self.idf[i] = -np.log(count_idf[i] / len(self.doc_token))\n",
        "\n",
        "        return self.idf\n",
        "\n",
        "    # TF-IDF\n",
        "    def cal_tfidf(self):\n",
        "        for i in range(len(self.doc_token)):\n",
        "            count_tfidf = [0 for a in range(len(self.word_ls))]\n",
        "            for j in range(len(self.word_ls)):\n",
        "                count_tfidf[j] = self.tf[i][j] * self.idf[j]\n",
        "            self.tf_idf.append(count_tfidf)\n",
        "\n",
        "        return self.tf_idf\n",
        "\n",
        "    # 결과 출력\n",
        "    def result_tfidf(self):\n",
        "        for i in range(len(self.doc_token)):\n",
        "            print(\"=========== doc {} ===========\".format(i))\n",
        "            df = pd.concat((pd.DataFrame(self.tf[i], index=self.word_ls, columns=['TF']), pd.DataFrame(self.idf, index=self.word_ls, columns=['idf']), pd.DataFrame(self.tf_idf[i],  index=self.word_ls, columns=['TF-IDF'])), axis=1)\n",
        "            print(df)\n",
        "\n",
        "    # 자동 실행\n",
        "    def run(self, doc):\n",
        "        self.make_token(doc)\n",
        "        self.count_word()\n",
        "        self.count_total()\n",
        "        self.cal_tf()\n",
        "        self.cal_idf()\n",
        "        self.cal_tfidf()\n",
        "        self.result_tfidf()"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVHKOBoQsplx",
        "colab_type": "text"
      },
      "source": [
        "### **2-2. TF-IDF Class 결과 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHToJYIBtK2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문서 리스트 생성\n",
        "doc = [\"The cat sat on my face I hate a cat\", \"The dog sat on my bed I love a dog\", \"The pet sat on my chair I love a pet\"]"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5SziYPFspW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = tf_idf()"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovJQf9bOvIE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "12321cfe-022f-470a-ce67-b10c289d0f53"
      },
      "source": [
        "tfidf.run(doc)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========== doc 0 ===========\n",
            "        TF       idf    TF-IDF\n",
            "dog    0.0  1.098612  0.000000\n",
            "my     0.1 -0.000000 -0.000000\n",
            "pet    0.0  1.098612  0.000000\n",
            "on     0.1 -0.000000 -0.000000\n",
            "The    0.1 -0.000000 -0.000000\n",
            "chair  0.0  1.098612  0.000000\n",
            "I      0.1 -0.000000 -0.000000\n",
            "hate   0.1  1.098612  0.109861\n",
            "a      0.1 -0.000000 -0.000000\n",
            "cat    0.2  1.098612  0.219722\n",
            "sat    0.1 -0.000000 -0.000000\n",
            "face   0.1  1.098612  0.109861\n",
            "bed    0.0  1.098612  0.000000\n",
            "love   0.0  0.405465  0.000000\n",
            "=========== doc 1 ===========\n",
            "        TF       idf    TF-IDF\n",
            "dog    0.2  1.098612  0.219722\n",
            "my     0.1 -0.000000 -0.000000\n",
            "pet    0.0  1.098612  0.000000\n",
            "on     0.1 -0.000000 -0.000000\n",
            "The    0.1 -0.000000 -0.000000\n",
            "chair  0.0  1.098612  0.000000\n",
            "I      0.1 -0.000000 -0.000000\n",
            "hate   0.0  1.098612  0.000000\n",
            "a      0.1 -0.000000 -0.000000\n",
            "cat    0.0  1.098612  0.000000\n",
            "sat    0.1 -0.000000 -0.000000\n",
            "face   0.0  1.098612  0.000000\n",
            "bed    0.1  1.098612  0.109861\n",
            "love   0.1  0.405465  0.040547\n",
            "=========== doc 2 ===========\n",
            "        TF       idf    TF-IDF\n",
            "dog    0.0  1.098612  0.000000\n",
            "my     0.1 -0.000000 -0.000000\n",
            "pet    0.2  1.098612  0.219722\n",
            "on     0.1 -0.000000 -0.000000\n",
            "The    0.1 -0.000000 -0.000000\n",
            "chair  0.1  1.098612  0.109861\n",
            "I      0.1 -0.000000 -0.000000\n",
            "hate   0.0  1.098612  0.000000\n",
            "a      0.1 -0.000000 -0.000000\n",
            "cat    0.0  1.098612  0.000000\n",
            "sat    0.1 -0.000000 -0.000000\n",
            "face   0.0  1.098612  0.000000\n",
            "bed    0.0  1.098612  0.000000\n",
            "love   0.1  0.405465  0.040547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZErBBvN9wuWt",
        "colab_type": "text"
      },
      "source": [
        "## **3. 모듈 이용해 TF-IDF 결과 확인**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcxGXLHiEUMi",
        "colab_type": "text"
      },
      "source": [
        "### **3-1. sklearn 이용**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCEqhbJuEYR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4dbaa04e-08b8-4757-a6de-0c0f5e459424"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "d1 = \"The cat sat on my face I hate a cat\"\n",
        "d2 = \"The dog sat on my bed I love a dog\"\n",
        "corpus = [d1, d2]\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "countv = count_vect.fit_transform(corpus)\n",
        "print(countv.toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록\n",
        "print(count_vect.vocabulary_) # 각 단어의 인덱스가 어떻게 부여됐는지 보여줌"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 2 0 1 1 0 1 1 1 1]\n",
            " [1 0 2 0 0 1 1 1 1 1]]\n",
            "{'the': 9, 'cat': 1, 'sat': 8, 'on': 7, 'my': 6, 'face': 3, 'hate': 4, 'dog': 2, 'bed': 0, 'love': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_AUZJc8ExB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a90a7ca1-727c-43d4-9121-7560c8503403"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "d1 = \"The cat sat on my face I hate a cat\"\n",
        "d2 = \"The dog sat on my bed I love a dog\"\n",
        "corpus = [d1, d2]\n",
        "\n",
        "tfidf_vect = TfidfVectorizer().fit(corpus)\n",
        "tfidfv = tfidf_vect.transform(corpus)\n",
        "print(tfidfv.toarray())\n",
        "print(tfidf_vect.vocabulary_)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.70600557 0.         0.35300279 0.35300279 0.\n",
            "  0.25116439 0.25116439 0.25116439 0.25116439]\n",
            " [0.35300279 0.         0.70600557 0.         0.         0.35300279\n",
            "  0.25116439 0.25116439 0.25116439 0.25116439]]\n",
            "{'the': 9, 'cat': 1, 'sat': 8, 'on': 7, 'my': 6, 'face': 3, 'hate': 4, 'dog': 2, 'bed': 0, 'love': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0aPJLivFuTC",
        "colab_type": "text"
      },
      "source": [
        "### **3-2 Gensim 활용**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwc4bVTtFHgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ea23df1-84f2-4177-c593-13e8dfd4f59a"
      },
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import TfidfModel\n",
        "from gensim import corpora\n",
        "\n",
        "d1 = \"The cat sat on my face I hate a cat\"\n",
        "d2 = \"The dog sat on my bed I love a dog\"\n",
        "corpus = [d1, d2]\n",
        "\n",
        "doc_ls = [doc.split() for doc in corpus]\n",
        "id2word = corpora.Dictionary(doc_ls) # fit dictionary\n",
        "corpus = [id2word.doc2bow(doc) for doc in doc_ls] # convert corpus to Bow format\n",
        "\n",
        "tfidf = TfidfModel(corpus) # fit model\n",
        "vector = tfidf[corpus[0]]\n",
        "vector"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 0.8164965809277261), (4, 0.4082482904638631), (5, 0.4082482904638631)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    }
  ]
}