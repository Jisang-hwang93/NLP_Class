{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06 TF-IDF Practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYJmWRBYAlBXmJpw/OYf8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jisang-hwang93/NLP_Class/blob/master/06%20TF%20IDF%20Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpJWXKsNc_ju",
        "colab_type": "text"
      },
      "source": [
        "# **Term Frequency - Inverse Document Frequency**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4X3zhR7MvW",
        "colab_type": "text"
      },
      "source": [
        "## **1. TF-IDF 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpU2G-66dFeG",
        "colab_type": "text"
      },
      "source": [
        "### **1-1. 데이터 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z69wPq4MN9JH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문서 리스트 생성\n",
        "doc = [\"The cat sat on my face I hate a cat\", \"The dog sat on my bed I love a dog\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFgSebdzdPcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "a7c64106-4dfd-4600-d1e6-ad155a1070a3"
      },
      "source": [
        "# 문서 토큰화\n",
        "doc_token = []\n",
        "tmp = []\n",
        "\n",
        "for doc_content in doc:\n",
        "    doc_token.append(doc_content.split())\n",
        "    tmp += doc_content.split()\n",
        "\n",
        "word_ls = list(set(tmp))\n",
        "\n",
        "doc_token, word_ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['The', 'cat', 'sat', 'on', 'my', 'face', 'I', 'hate', 'a', 'cat'],\n",
              "  ['The', 'dog', 'sat', 'on', 'my', 'bed', 'I', 'love', 'a', 'dog']],\n",
              " ['hate',\n",
              "  'a',\n",
              "  'dog',\n",
              "  'my',\n",
              "  'I',\n",
              "  'love',\n",
              "  'cat',\n",
              "  'on',\n",
              "  'bed',\n",
              "  'sat',\n",
              "  'The',\n",
              "  'face'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_0kvGVsSFWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "9e631d59-6fd3-4644-a6c7-f10494385371"
      },
      "source": [
        "# 문서별 단어 빈도수\n",
        "dic = []\n",
        "\n",
        "# 딕셔너리 안에 넣기\n",
        "for i in range(len(doc_token)):\n",
        "    dic_tmp = {}\n",
        "    count_tmp = 0\n",
        "    for word in word_ls:\n",
        "        dic_tmp[word] = doc_token[i].count(word)\n",
        "    dic.append(dic_tmp)\n",
        "\n",
        "dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'I': 1,\n",
              "  'The': 1,\n",
              "  'a': 1,\n",
              "  'bed': 0,\n",
              "  'cat': 2,\n",
              "  'dog': 0,\n",
              "  'face': 1,\n",
              "  'hate': 1,\n",
              "  'love': 0,\n",
              "  'my': 1,\n",
              "  'on': 1,\n",
              "  'sat': 1},\n",
              " {'I': 1,\n",
              "  'The': 1,\n",
              "  'a': 1,\n",
              "  'bed': 1,\n",
              "  'cat': 0,\n",
              "  'dog': 2,\n",
              "  'face': 0,\n",
              "  'hate': 0,\n",
              "  'love': 1,\n",
              "  'my': 1,\n",
              "  'on': 1,\n",
              "  'sat': 1}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lV7SW8SSehW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea8a7891-63a6-4c30-abe0-8838b7e02ce7"
      },
      "source": [
        "# 전체 토큰 빈도 계산\n",
        "total = []\n",
        "\n",
        "for i in range(len(dic)):\n",
        "    total_num = 0\n",
        "    for j in dic[i].values():\n",
        "        total_num += j\n",
        "    total.append(total_num)\n",
        "\n",
        "total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnCtDsTASs8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "b0cb20cc-6860-480d-e8b1-3dc75a59d8bb"
      },
      "source": [
        "# TF 계산\n",
        "tf = []\n",
        "\n",
        "\n",
        "for total_value, i in enumerate(total):\n",
        "    tf_tmp = {}\n",
        "    for dic_value in dic:\n",
        "        print(dic_value)\n",
        "        tf_tmp[word] = dic_value[word] / total_value\n",
        "    tf.append(tf_tmp)\n",
        "\n",
        "tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hate': 1, 'a': 1, 'dog': 0, 'my': 1, 'I': 1, 'love': 0, 'cat': 2, 'on': 1, 'bed': 0, 'sat': 1, 'The': 1, 'face': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-87206e694437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdic_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtf_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2vWxsi_VhuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c2a9c6b8-f2b3-4028-bb9a-57d5831516ee"
      },
      "source": [
        "# IDF 계산\n",
        "idf = {}\n",
        "\n",
        "for word in index_loc:\n",
        "    if word in doc1:\n",
        "        if word in idf.keys(): \n",
        "            idf[word] = idf[word] + 1\n",
        "        else:\n",
        "            idf[word] =+ 1\n",
        "    if word in doc2:\n",
        "        if word in idf.keys() :\n",
        "            idf[word] = idf[word] + 1\n",
        "        else:\n",
        "            idf[word] =+ 1\n",
        "    \n",
        "for word in idf:\n",
        "    idf[word] = -np.log(idf[word]/2)\n",
        "\n",
        "print(idf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': -0.0, 'cat': 0.6931471805599453, 'sat': -0.0, 'on': -0.0, 'my': -0.0, 'face': 0.6931471805599453, 'I': -0.0, 'hate': 0.6931471805599453, 'a': -0.0, 'dog': 0.6931471805599453, 'bed': 0.6931471805599453, 'love': 0.6931471805599453}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1VxS5M1ao4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2f003589-4ba9-4638-d72f-0775533f2cca"
      },
      "source": [
        "# TF-IDF\n",
        "result1 = {}\n",
        "result2 = {}\n",
        "for word in index_loc:\n",
        "    result1[word] = tf1[word]*idf[word]\n",
        "    result2[word] = tf2[word]*idf[word]\n",
        "\n",
        "print(result1,'\\n',result2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': -0.0, 'cat': 0.13862943611198905, 'sat': -0.0, 'on': -0.0, 'my': -0.0, 'face': 0.06931471805599453, 'I': -0.0, 'hate': 0.06931471805599453, 'a': -0.0, 'dog': 0.0, 'bed': 0.0, 'love': 0.0} \n",
            " {'The': -0.0, 'cat': 0.0, 'sat': -0.0, 'on': -0.0, 'my': -0.0, 'face': 0.0, 'I': -0.0, 'hate': 0.0, 'a': -0.0, 'dog': 0.13862943611198905, 'bed': 0.06931471805599453, 'love': 0.06931471805599453}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSH9mxW59AaI",
        "colab_type": "text"
      },
      "source": [
        "# **2. Class로 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0u8RsAwdwdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from collections import defaultdict\n",
        "from numpy import array, argmax\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class TF_IDF():\n",
        "    def __init__(self):\n",
        "        self.doc1_token = []\n",
        "        self.doc2_token = []\n",
        "        self.word_ls = []\n",
        "        self.index_loc = []\n",
        "        self.dic1 = {}\n",
        "        self.dic2 = {}\n",
        "        self.total1 = 0\n",
        "        self.total2 = 0\n",
        "        self.tf1 = {}\n",
        "        self.tf2 = {}\n",
        "        self.idf = {}\n",
        "        self.result1 = {}\n",
        "        self.result2 = {}\n",
        "\n",
        "    # 문서 토큰화\n",
        "    def doc_split(self, doc1, doc2):\n",
        "        self.doc1_token = doc1.split()\n",
        "        self.doc2_token = doc2.split()\n",
        "        self.word_ls = self.doc1_token + self.doc2_token\n",
        "        \n",
        "        return self.doc1_token, self.doc2_token, self.word_ls\n",
        "\n",
        "    # 토큰별 등장 횟수 측정 함수\n",
        "    def token_index(self):\n",
        "        # 토큰 Index 생성\n",
        "        word2id_dic = defaultdict(lambda : len(word2id_dic))\n",
        "        for word in self.word_ls:\n",
        "            word2id_dic[word]\n",
        "        self.index_loc = word2id_dic\n",
        "        # 딕셔너리 안에 넣기\n",
        "        for word in self.index_loc:\n",
        "            self.dic1[word] = self.doc1_token.count(word)\n",
        "            self.dic2[word] = self.doc2_token.count(word)\n",
        "        \n",
        "        return self.dic1, self.dic2\n",
        "\n",
        "    # 전체 토큰 빈도 계산\n",
        "    def count_token(self):\n",
        "        for i in self.dic1.values():\n",
        "            self.total1 += i\n",
        "        for i in self.dic2.values():\n",
        "            self.total2 += i\n",
        "        return self.total1, self.total2\n",
        "\n",
        "    # TF 계산\n",
        "    def cal_TF(self):\n",
        "        for word in self.index_loc:\n",
        "            self.tf1[word] = self.dic1[word] / self.total1\n",
        "            self.tf2[word] = self.dic2[word] / self.total2\n",
        "        return self.tf1, self.tf2\n",
        "\n",
        "    # IDF 계산\n",
        "    def cal_IDF(self):\n",
        "        for word in self.index_loc:\n",
        "            if word in self.doc1_token:\n",
        "                if word in self.idf.keys():\n",
        "                    self.idf[word] = self.idf[word] + 1\n",
        "        print(self.idf)\n",
        "        # #         else:\n",
        "        # #             self.idf[word] =+ 1\n",
        "        # #     if word in self.doc2_token:\n",
        "        # #         if word in self.idf.keys() :\n",
        "        # #             self.idf[word] = self.idf[word] + 1\n",
        "        # #         else:\n",
        "        # #             self.idf[word] =+ 1\n",
        "        # # for word in self.idf:\n",
        "        # #     self.idf[word] = -np.log(self.idf[word]/2)\n",
        "\n",
        "        # return self.idf\n",
        "\n",
        "    # TF-IDF\n",
        "    def cal_TFIDF(self):\n",
        "        for word in self.index_loc:\n",
        "            self.result1[word] = self.tf1[word]*self.idf[word]\n",
        "            self.result2[word] = self.tf2[word]*self.idf[word]\n",
        "        return self.result1, self.result2\n",
        "\n",
        "    def run(self, doc1, doc2):\n",
        "        self.doc_split(doc1, doc2)\n",
        "        self.token_index()\n",
        "        self.count_token\n",
        "        self.cal_TF()\n",
        "        self.cal_IDF()\n",
        "        self.cal_TFIDF()\n",
        "\n",
        "        print(self.result1, self.result2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0reDF_6KKXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문서 리스트 생성\n",
        "doc1 = \"The cat sat on my face I hate a cat\"\n",
        "doc2 = \"The dog sat on my bed I love a dog\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbHh21T7KBNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TF_IDF()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEim3XHeL62-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "54565f03-d940-48fe-fb18-60b756401152"
      },
      "source": [
        "tfidf.doc_split(doc1, doc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['The', 'cat', 'sat', 'on', 'my', 'face', 'I', 'hate', 'a', 'cat'],\n",
              " ['The', 'dog', 'sat', 'on', 'my', 'bed', 'I', 'love', 'a', 'dog'],\n",
              " ['The',\n",
              "  'cat',\n",
              "  'sat',\n",
              "  'on',\n",
              "  'my',\n",
              "  'face',\n",
              "  'I',\n",
              "  'hate',\n",
              "  'a',\n",
              "  'cat',\n",
              "  'The',\n",
              "  'dog',\n",
              "  'sat',\n",
              "  'on',\n",
              "  'my',\n",
              "  'bed',\n",
              "  'I',\n",
              "  'love',\n",
              "  'a',\n",
              "  'dog'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkNbBRUyUgza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "dd9b6324-59bb-4ea7-b4bb-d098c7121ca5"
      },
      "source": [
        "tfidf.token_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'I': 1,\n",
              "  'The': 1,\n",
              "  'a': 1,\n",
              "  'bed': 0,\n",
              "  'cat': 2,\n",
              "  'dog': 0,\n",
              "  'face': 1,\n",
              "  'hate': 1,\n",
              "  'love': 0,\n",
              "  'my': 1,\n",
              "  'on': 1,\n",
              "  'sat': 1},\n",
              " {'I': 1,\n",
              "  'The': 1,\n",
              "  'a': 1,\n",
              "  'bed': 1,\n",
              "  'cat': 0,\n",
              "  'dog': 2,\n",
              "  'face': 0,\n",
              "  'hate': 0,\n",
              "  'love': 1,\n",
              "  'my': 1,\n",
              "  'on': 1,\n",
              "  'sat': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLGVRNktUga5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59155fe0-9efb-40a6-bc21-573c5742882d"
      },
      "source": [
        "tfidf.count_token()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpTTxb_RUgg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "1e714e73-988a-43be-de15-8d97fda254e6"
      },
      "source": [
        "tfidf.cal_TF()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'I': 0.1,\n",
              "  'The': 0.1,\n",
              "  'a': 0.1,\n",
              "  'bed': 0.0,\n",
              "  'cat': 0.2,\n",
              "  'dog': 0.0,\n",
              "  'face': 0.1,\n",
              "  'hate': 0.1,\n",
              "  'love': 0.0,\n",
              "  'my': 0.1,\n",
              "  'on': 0.1,\n",
              "  'sat': 0.1},\n",
              " {'I': 0.1,\n",
              "  'The': 0.1,\n",
              "  'a': 0.1,\n",
              "  'bed': 0.1,\n",
              "  'cat': 0.0,\n",
              "  'dog': 0.2,\n",
              "  'face': 0.0,\n",
              "  'hate': 0.0,\n",
              "  'love': 0.1,\n",
              "  'my': 0.1,\n",
              "  'on': 0.1,\n",
              "  'sat': 0.1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaABGuXtUge1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ac41571-a038-471f-d5c4-f5f3fa263062"
      },
      "source": [
        "tfidf.cal_IDF()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XupbMak0UgSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcxGXLHiEUMi",
        "colab_type": "text"
      },
      "source": [
        "## **3.2 sklearn 이용하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCEqhbJuEYR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "d1 = \"The cat sat on my face I hate a cat\"\n",
        "d2 = \"The dog sat on my bed I love a dog\"\n",
        "corpus = [d1, d2]\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "countv = count_vect.fit_transform(corpus)\n",
        "print(countv.toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록\n",
        "print(count_vect.vocabulary_) # 각 단어의 인덱스가 어떻게 부여됐는지 보여줌"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_AUZJc8ExB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "d1 = \"The cat sat on my face I hate a cat\"\n",
        "d2 = \"The dog sat on my bed I love a dog\"\n",
        "corpus = [d1, d2]\n",
        "\n",
        "tfidf_vect = TfidfVectorizer().fit(corpus)\n",
        "tfidfv = tfidf_vect.transform(corpus)\n",
        "print(tfidfv.toarray())\n",
        "print(tfidf_vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0aPJLivFuTC",
        "colab_type": "text"
      },
      "source": [
        "## **3.3 gensim 활용**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwc4bVTtFHgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import TfidfModel\n",
        "from gensim import corpora\n",
        "\n",
        "d1 = \"The cat sat on my face I hate a cat\"\n",
        "d2 = \"The dog sat on my bed I love a dog\"\n",
        "corpus = [d1, d2]\n",
        "\n",
        "doc_ls = [doc.split() for doc in corpus]\n",
        "id2word = corpora.Dictionary(doc_ls) # fit dictionary\n",
        "corpus = [id2word.doc2bow(doc) for doc in doc_ls] # convert corpus to Bow format\n",
        "\n",
        "tfidf = TfidfModel(corpus) # fit model\n",
        "vector = tfidf[corpus[0]]\n",
        "vector"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}