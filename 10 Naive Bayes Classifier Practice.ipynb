{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_Naive_Bayes_Classifier_Practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqUx1xQm1H6cg0MLoVVSwf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jisang-hwang93/NLP_Class/blob/master/10%20Naive%20Bayes%20Classifier%20Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaSOTmauHXe",
        "colab_type": "text"
      },
      "source": [
        "# **Document Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzB2pH_JuMKD",
        "colab_type": "text"
      },
      "source": [
        "## **1. Naive Bayes Classifier 구현**\n",
        "**스팸 메일 필터링**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPAhReDDugYU",
        "colab_type": "text"
      },
      "source": [
        "### **1-1. 데이터 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qpVQiFT46cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 메일과 메일의 종류 데이터\n",
        "mail = ['me free lottery',\n",
        "        'free get free you',\n",
        "        'you free scholarship',\n",
        "        'free to contact me',\n",
        "        'you won award',\n",
        "        'you ticket lottery']\n",
        "\n",
        "mail_type = [\"spam\", \"spam\", \"normal\", \"normal\", \"normal\", \"spam\"]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUq3mhrx9Xse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "8276627f-feed-4d11-dc7a-bdef6cc482a3"
      },
      "source": [
        "# 각 문장 토큰화\n",
        "lines = []\n",
        "tokens = []\n",
        "\n",
        "for i in range(len(mail)):\n",
        "    lines.append(mail[i].split(\" \"))\n",
        "    # 단어 뭉치 생성\n",
        "    for word in lines[i]:\n",
        "        tokens.append(word)\n",
        "tokens = list(set(tokens))\n",
        "\n",
        "# 메일의 종류\n",
        "types = list(set(mail_type))\n",
        "\n",
        "lines, tokens, types"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['me', 'free', 'lottery'],\n",
              "  ['free', 'get', 'free', 'you'],\n",
              "  ['you', 'free', 'scholarship'],\n",
              "  ['free', 'to', 'contact', 'me'],\n",
              "  ['you', 'won', 'award'],\n",
              "  ['you', 'ticket', 'lottery']],\n",
              " ['ticket',\n",
              "  'free',\n",
              "  'you',\n",
              "  'lottery',\n",
              "  'scholarship',\n",
              "  'award',\n",
              "  'contact',\n",
              "  'won',\n",
              "  'get',\n",
              "  'to',\n",
              "  'me'],\n",
              " ['spam', 'normal'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynmPb7p9rdKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ae491062-8556-4c36-f4d5-f28eb8c201d6"
      },
      "source": [
        "# 메일 분류 확인\n",
        "import pandas as pd\n",
        "\n",
        "mail_classify = {\"메일\" : lines, \"분류\": mail_type}\n",
        "df = pd.DataFrame(mail_classify)\n",
        "\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>메일</th>\n",
              "      <th>분류</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[me, free, lottery]</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[free, get, free, you]</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[you, free, scholarship]</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[free, to, contact, me]</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[you, won, award]</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[you, ticket, lottery]</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         메일      분류\n",
              "0       [me, free, lottery]    spam\n",
              "1    [free, get, free, you]    spam\n",
              "2  [you, free, scholarship]  normal\n",
              "3   [free, to, contact, me]  normal\n",
              "4         [you, won, award]  normal\n",
              "5    [you, ticket, lottery]    spam"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DezCHfJjmiQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba9e48d5-27b3-41da-92a5-d20d51a40873"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "spam_word = []\n",
        "norm_word = []\n",
        "total_spam = 0\n",
        "total_norm = 0\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    count_spam = 0\n",
        "    count_norm = 0\n",
        "    spam_mail = 0\n",
        "    norm_mail = 0\n",
        "    for j in range(len(lines)):\n",
        "        if mail_classify[\"분류\"][j] == \"spam\":\n",
        "            spam_mail += 1\n",
        "            if tokens[i] in lines[j]:\n",
        "                count_spam += lines[j].count(tokens[i])\n",
        "        if mail_classify[\"분류\"][j] == \"normal\":\n",
        "            norm_mail += 1\n",
        "            if tokens[i] in lines[j]:\n",
        "                count_norm += lines[j].count(tokens[i])\n",
        "\n",
        "    spam_word.append(count_spam)\n",
        "    norm_word.append(count_norm)\n",
        "    total_spam += count_spam\n",
        "    total_norm += count_norm\n",
        "\n",
        "# 사전확률 구하기\n",
        "norm_prior = norm_mail / (spam_mail + norm_mail)\n",
        "spam_prior = spam_mail / (spam_mail + norm_mail)\n",
        "\n",
        "total_spam, total_norm, norm_prior, spam_prior"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10, 0.5, 0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjNdEC6Gusmt",
        "colab_type": "text"
      },
      "source": [
        "### **1-2. Laplace Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C355gHdXqXpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Laplace Smoothing\n",
        "laplace_spam = []\n",
        "laplace_norm = []\n",
        "k = 0.5\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    laplace_spam.append((k+spam_word[i])/(2*k+total_spam)*100)\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    laplace_norm.append((k+norm_word[i])/(2*k+total_norm)*100)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "val_rfvg0ZF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "307e6b09-3fbd-42c0-a240-36aab5e731db"
      },
      "source": [
        "word_table = np.array([spam_word, norm_word, laplace_spam, laplace_norm])\n",
        "\n",
        "df = pd.DataFrame(word_table.T, index=tokens, columns=[\"spam\", \"normal\", \"P(w|spam)\", \"P(w|normal)\"])\n",
        "df.sort_index(axis=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spam</th>\n",
              "      <th>normal</th>\n",
              "      <th>P(w|spam)</th>\n",
              "      <th>P(w|normal)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>award</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contact</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>free</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>31.818182</td>\n",
              "      <td>22.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>get</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>4.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lottery</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.727273</td>\n",
              "      <td>4.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>me</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>13.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scholarship</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ticket</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>4.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>won</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>you</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.727273</td>\n",
              "      <td>22.727273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             spam  normal  P(w|spam)  P(w|normal)\n",
              "award         0.0     1.0   4.545455    13.636364\n",
              "contact       0.0     1.0   4.545455    13.636364\n",
              "free          3.0     2.0  31.818182    22.727273\n",
              "get           1.0     0.0  13.636364     4.545455\n",
              "lottery       2.0     0.0  22.727273     4.545455\n",
              "me            1.0     1.0  13.636364    13.636364\n",
              "scholarship   0.0     1.0   4.545455    13.636364\n",
              "ticket        1.0     0.0  13.636364     4.545455\n",
              "to            0.0     1.0   4.545455    13.636364\n",
              "won           0.0     1.0   4.545455    13.636364\n",
              "you           2.0     2.0  22.727273    22.727273"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPCZz0z2uwu1",
        "colab_type": "text"
      },
      "source": [
        "### **1-3. Log 이용**\n",
        "**Log의 성질을 활용. 곱셈을 덧셈으로 변환해 Underflow를 방지함**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTrBEC5_BIBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 로그 이용 언더 플로우\n",
        "log_spam = []\n",
        "log_norm = []\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    log_spam.append(np.log(laplace_spam[i]/100))\n",
        "    log_norm.append(np.log(laplace_norm[i]/100))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfhaSmtQ8kpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "1cbfe0be-3ed6-47a4-e7a4-f6baf3f20a6e"
      },
      "source": [
        "word_table = np.array([spam_word, norm_word, laplace_spam, laplace_norm, log_spam, log_norm])\n",
        "\n",
        "df = pd.DataFrame(word_table.T, index=tokens, columns=[\"spam\", \"normal\", \"P(w|spam)\", \"P(w|normal)\", \"Log(P(w|spam))\", \"Log(P(w|normal))\"])\n",
        "df.sort_index(axis=0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spam</th>\n",
              "      <th>normal</th>\n",
              "      <th>P(w|spam)</th>\n",
              "      <th>P(w|normal)</th>\n",
              "      <th>Log(P(w|spam))</th>\n",
              "      <th>Log(P(w|normal))</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>award</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>-3.091042</td>\n",
              "      <td>-1.992430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contact</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>-3.091042</td>\n",
              "      <td>-1.992430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>free</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>31.818182</td>\n",
              "      <td>22.727273</td>\n",
              "      <td>-1.145132</td>\n",
              "      <td>-1.481605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>get</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>-1.992430</td>\n",
              "      <td>-3.091042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lottery</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.727273</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>-1.481605</td>\n",
              "      <td>-3.091042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>me</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>-1.992430</td>\n",
              "      <td>-1.992430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scholarship</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>-3.091042</td>\n",
              "      <td>-1.992430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ticket</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>-1.992430</td>\n",
              "      <td>-3.091042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>-3.091042</td>\n",
              "      <td>-1.992430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>won</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>13.636364</td>\n",
              "      <td>-3.091042</td>\n",
              "      <td>-1.992430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>you</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.727273</td>\n",
              "      <td>22.727273</td>\n",
              "      <td>-1.481605</td>\n",
              "      <td>-1.481605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             spam  normal  ...  Log(P(w|spam))  Log(P(w|normal))\n",
              "award         0.0     1.0  ...       -3.091042         -1.992430\n",
              "contact       0.0     1.0  ...       -3.091042         -1.992430\n",
              "free          3.0     2.0  ...       -1.145132         -1.481605\n",
              "get           1.0     0.0  ...       -1.992430         -3.091042\n",
              "lottery       2.0     0.0  ...       -1.481605         -3.091042\n",
              "me            1.0     1.0  ...       -1.992430         -1.992430\n",
              "scholarship   0.0     1.0  ...       -3.091042         -1.992430\n",
              "ticket        1.0     0.0  ...       -1.992430         -3.091042\n",
              "to            0.0     1.0  ...       -3.091042         -1.992430\n",
              "won           0.0     1.0  ...       -3.091042         -1.992430\n",
              "you           2.0     2.0  ...       -1.481605         -1.481605\n",
              "\n",
              "[11 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJnwm6BqzKni",
        "colab_type": "text"
      },
      "source": [
        "### **1-4. 스팸 확률 구하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNzH3uRrAjbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08064187-5e9e-466e-fc5e-3b770a66e455"
      },
      "source": [
        "# 스팸 필터링 : 입력값\n",
        "check_list = \"free lottery\"\n",
        "\n",
        "check_token = []\n",
        "\n",
        "check_token.append(check_list.split(\" \"))\n",
        "\n",
        "check_token"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['free', 'lottery']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tLr93uOzQGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8b3b7e01-47aa-4089-c953-fab3b105bcb0"
      },
      "source": [
        "# 입력 토큰 로그들의 합\n",
        "import math\n",
        "\n",
        "spam_filter = 0\n",
        "norm_filter = 0\n",
        "\n",
        "for i in range(len(check_token[0])):\n",
        "    spam_filter += df['Log(P(w|spam))'][check_token[0][i]]\n",
        "    norm_filter += df['Log(P(w|normal))'][check_token[0][i]]\n",
        "\n",
        "spam_filter, norm_filter\n",
        "# 입력 토큰 로그합과 사전확률 로그의 합\n",
        "spam_filter = math.exp(spam_filter + np.log(spam_prior))\n",
        "norm_filter = math.exp(norm_filter + np.log(norm_prior))\n",
        "\n",
        "# 스팸/정상 메일일 확률\n",
        "spam_prob = spam_filter / (spam_filter + norm_filter)\n",
        "norm_prob = norm_filter / (spam_filter + norm_filter)\n",
        "\n",
        "spam_filter, norm_filter, spam_prob, norm_prob"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.03615702479338842,\n",
              " 0.00516528925619835,\n",
              " 0.8749999999999999,\n",
              " 0.12500000000000008)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmh12tB_5EyO",
        "colab_type": "text"
      },
      "source": [
        "### **1-5. 최종 결과**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccTMHNWL3pBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3e684f8a-62f5-4ccf-a4d5-789963192327"
      },
      "source": [
        "print(\"{}라는 토큰이 있는 메일이 스팸일 확률 : {:.2f}%\".format(check_list, spam_prob*100))\n",
        "print(\"{}라는 토큰이 있는 메일이 정상일 확률 : {:.2f}%\".format(check_list, norm_prob*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "free lottery라는 토큰이 있는 메일이 스팸일 확률 : 87.50%\n",
            "free lottery라는 토큰이 있는 메일이 정상일 확률 : 12.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1O5JseJ5_Bi",
        "colab_type": "text"
      },
      "source": [
        "## **2. Class를 이용한 Naive Bayes Classifier 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UBtGW3W4MH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class NBC():\n",
        "    def __init__(self):\n",
        "        self.lines = []\n",
        "        self.tokens = []\n",
        "        self.mail_classify = {}\n",
        "        self.spam_prior = 0\n",
        "        self.norm_prior = 0\n",
        "        self.spam_word = []\n",
        "        self.norm_word = []\n",
        "        self.total_spam = 0\n",
        "        self.total_norm = 0\n",
        "        self.df = []\n",
        "        self.laplace_spam = []\n",
        "        self.laplace_norm = []\n",
        "        self.log_spam = []\n",
        "        self.log_norm = []\n",
        "        self.check_token = []\n",
        "        self.spam_filter = 0\n",
        "        self.norm_filter = 0\n",
        "        self.spam_prob = 0\n",
        "        self.nrom_prob = 0\n",
        "\n",
        "    # 메일 분류\n",
        "    def classify_mail(self, mail, mail_type):\n",
        "        for i in range(len(mail)):\n",
        "            self.lines.append(mail[i].split(\" \"))\n",
        "            # 단어 뭉치 생성\n",
        "            for word in self.lines[i]:\n",
        "                self.tokens.append(word)\n",
        "        self.tokens = list(set(self.tokens))\n",
        "        # 메일 분류 확인\n",
        "        self.mail_classify = {\"메일\" : self.lines, \"분류\": mail_type}\n",
        "\n",
        "        return lines, self.tokens, self.mail_classify\n",
        "\n",
        "    # 사전 확률과 토큰별 메일 개수 계산\n",
        "    def count_mail(self):\n",
        "        for i in range(len(self.tokens)):\n",
        "            count_spam = 0\n",
        "            count_norm = 0\n",
        "            for j in range(len(self.lines)):\n",
        "                if self.mail_classify[\"분류\"][j] == \"spam\":\n",
        "                    if self.tokens[i] in self.lines[j]:\n",
        "                        count_spam += self.lines[j].count(self.tokens[i])\n",
        "                if self.mail_classify[\"분류\"][j] == \"normal\":\n",
        "                    if self.tokens[i] in self.lines[j]:\n",
        "                        count_norm += self.lines[j].count(self.tokens[i])\n",
        "            # 단어별 스팸, 정상 메일 개수 계산\n",
        "            self.spam_word.append(count_spam)\n",
        "            self.norm_word.append(count_norm)\n",
        "            # 총 스팸, 정상 단어 개수\n",
        "            self.total_spam += count_spam\n",
        "            self.total_norm += count_norm\n",
        "\n",
        "        return self.spam_prior, self.norm_prior, self.total_spam, self.total_norm\n",
        "\n",
        "    # Laplace Smoothing 계산\n",
        "    def laplace_smoothing(self, k):\n",
        "        for i in range(len(self.tokens)):\n",
        "            self.laplace_spam.append((k+self.spam_word[i])/(2*self.spam_prior+self.total_spam)*100)\n",
        "            self.laplace_norm.append((k+self.norm_word[i])/(2*self.norm_prior+self.total_norm)*100)\n",
        "        \n",
        "        return self.laplace_spam, self.laplace_norm\n",
        "\n",
        "    # 로그 이용 언더 플로우\n",
        "    def log_calculate(self):\n",
        "        for i in range(len(self.tokens)):\n",
        "            self.log_spam.append(np.log(self.laplace_spam[i]/100))\n",
        "            self.log_norm.append(np.log(self.laplace_norm[i]/100))\n",
        "        # 결과 출력\n",
        "        word_table = np.array([self.spam_word, self.norm_word, self.laplace_spam, self.laplace_norm, self.log_spam, self.log_norm])\n",
        "        self.df = pd.DataFrame(word_table.T, index=self.tokens, columns=[\"spam\", \"normal\", \"P(w|spam)\", \"P(w|normal)\", \"Log(P(w|spam))\", \"Log(P(w|normal))\"])\n",
        "        \n",
        "        return self.df.sort_index(axis=0)\n",
        "\n",
        "    # 스팸 필터링 : 입력값\n",
        "    def list_check(self, check_list):\n",
        "        self.check_token.append(check_list.split(\" \"))\n",
        "\n",
        "        return self.check_token\n",
        "\n",
        "    # 스팸 필터링\n",
        "    def spam_filtering(self):\n",
        "        for i in range(len(self.check_token[0])):\n",
        "            self.spam_filter += self.df['Log(P(w|spam))'][self.check_token[0][i]]\n",
        "            self.norm_filter += self.df['Log(P(w|normal))'][self.check_token[0][i]]\n",
        "        # 입력 토큰 로그합과 사전확률 로그의 합\n",
        "        self.spam_filter = math.exp(self.spam_filter + np.log(self.spam_prior))\n",
        "        self.norm_filter = math.exp(self.norm_filter + np.log(self.norm_prior))\n",
        "\n",
        "        return self.spam_filter, self.norm_filter\n",
        "    \n",
        "    # 스팸/정상 메일일 확률\n",
        "    def spam_probability(self):\n",
        "        self.spam_prob = self.spam_filter / (self.spam_filter + self.norm_filter)\n",
        "        self.norm_prob = self.norm_filter / (self.spam_filter + self.norm_filter)\n",
        "\n",
        "        return self.spam_prob, self.norm_prob\n",
        "\n",
        "    # 결과값 출력\n",
        "    def spam_result(self):\n",
        "        print(\"{}라는 토큰이 있는 메일이 스팸일 확률 : {:.2f}%\".format(self.check_token[0], self.spam_prob*100))\n",
        "        print(\"{}라는 토큰이 있는 메일이 정상일 확률 : {:.2f}%\".format(self.check_token[0], self.norm_prob*100))\n",
        "\n",
        "    def run(self, mail, mail_type, check_list, k):\n",
        "        self.classify_mail(mail, mail_type)\n",
        "        self.count_mail()\n",
        "        self.laplace_smoothing(k)\n",
        "        self.log_calculate()\n",
        "        self.list_check(check_list)\n",
        "        self.spam_filtering()\n",
        "        self.spam_probability()\n",
        "        self.spam_result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXVObQJK6-2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 메일과 메일의 종류 데이터\n",
        "mail = ['me free lottery',\n",
        "        'free get free you',\n",
        "        'you free scholarship',\n",
        "        'free to contact me',\n",
        "        'you won award',\n",
        "        'you ticket lottery']\n",
        "\n",
        "mail_type = [\"spam\", \"spam\", \"normal\", \"normal\", \"normal\", \"spam\"]\n",
        "\n",
        "check = \"get me\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTDLhz9s7r7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nbc = NBC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOdkwrfc_Vh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f76bb157-ad67-48b9-f0a7-906bc2c07c98"
      },
      "source": [
        "nbc.run(mail, mail_type, check, 0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['get', 'me']라는 토큰이 있는 메일이 스팸일 확률 : 75.00%\n",
            "['get', 'me']라는 토큰이 있는 메일이 정상일 확률 : 25.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZh4OzlStrWw",
        "colab_type": "text"
      },
      "source": [
        "## **3. sklearn을 활용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMqC_TmLwFOr",
        "colab_type": "text"
      },
      "source": [
        "### **3-1. 뉴스 데이터 다운로드**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOQau8SMv2to",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "b973efb9-4e6a-44d4-b4ea-af8c0eb1c06b"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset = 'train', shuffle = True)\n",
        "print(twenty_train.target_names) # 뉴스 카테고리 출력\n",
        "print(twenty_train.data[0]) # 뉴스 데이터 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEwxs53fw6PK",
        "colab_type": "text"
      },
      "source": [
        "### **3-2. 문서 분류(파이프 라인 이용)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pryoCcPJn99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clif', MultinomialNB()), ])\n",
        "\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkMrLXk5zDPz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17ec645a-3622-4519-902f-157e82e056fb"
      },
      "source": [
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgIQZpKAxLpZ",
        "colab_type": "text"
      },
      "source": [
        "### **3-3. Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae2SktMBxJru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "outputId": "d0ba803d-c49c-4ec7-f0df-ce73f51e04cf"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_clf = {'vect__ngram_range' : [(1, 1), (1, 2)],\n",
        "                 'tfidf__use_idf' : (True, False),\n",
        "}\n",
        "gs_clf = GridSearchCV(text_clf, parameters_clf, n_jobs=-1, verbose=2)\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
        "print(\"Best Score : {0}\".format(gs_clf.best_score_))\n",
        "print(\"Best Parameters Set : \")\n",
        "best_parameters = gs_clf.best_estimator_.get_params()\n",
        "for param_name in sorted(list(best_parameters.keys())):\n",
        "    print(\"\\t{0} : {1}\".format(param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Score : 0.8518650274101537\n",
            "Best Parameters Set : \n",
            "\tclif : MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "\tclif__alpha : 1.0\n",
            "\tclif__class_prior : None\n",
            "\tclif__fit_prior : True\n",
            "\tmemory : None\n",
            "\tsteps : [('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)), ('clif', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]\n",
            "\ttfidf : TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
            "\ttfidf__norm : l2\n",
            "\ttfidf__smooth_idf : True\n",
            "\ttfidf__sublinear_tf : False\n",
            "\ttfidf__use_idf : True\n",
            "\tvect : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n",
            "\tvect__analyzer : word\n",
            "\tvect__binary : False\n",
            "\tvect__decode_error : strict\n",
            "\tvect__dtype : <class 'numpy.int64'>\n",
            "\tvect__encoding : utf-8\n",
            "\tvect__input : content\n",
            "\tvect__lowercase : True\n",
            "\tvect__max_df : 1.0\n",
            "\tvect__max_features : None\n",
            "\tvect__min_df : 1\n",
            "\tvect__ngram_range : (1, 2)\n",
            "\tvect__preprocessor : None\n",
            "\tvect__stop_words : None\n",
            "\tvect__strip_accents : None\n",
            "\tvect__token_pattern : (?u)\\b\\w\\w+\\b\n",
            "\tvect__tokenizer : None\n",
            "\tvect__vocabulary : None\n",
            "\tverbose : False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHMJe9050jIC",
        "colab_type": "text"
      },
      "source": [
        "### **3-4. Parameter 적용**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YesRlvNW0HPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "539aefe3-39f3-40fb-8ec0-97de44ed8b5d"
      },
      "source": [
        "import numpy as np\n",
        "predicted = gs_clf.best_estimator_.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.765400955921402"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}